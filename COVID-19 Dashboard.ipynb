{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import datetime\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Timeseries Data\n",
    "\n",
    "Add documentation about the time series here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import get_time_series\n",
    "\n",
    "confirmed, deaths, recovered, time_series_dates = get_time_series(local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the Daily Reports \n",
    "\n",
    "Add documentation about these reports here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import get_daily_reports\n",
    "\n",
    "daily_report_data, daily_report_dates = get_daily_reports(local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Done Gathering Data.\n",
    "\n",
    "Let's merge the time_series_data into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import data_by_area\n",
    "from data import us_confirmed \n",
    "\n",
    "data = data_by_area(area='Nebraska', col='State', df=us_confirmed)\n",
    "data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_by_area(area='US', col='Country/Region', df=None):\n",
    "\tfrom data import time_series_date_list\n",
    "\tprint(col)\n",
    "\tdata =pd.Series(\n",
    "\t\t[df.loc[(df[col] == area)][date].sum() for date in time_series_date_list],\n",
    "\t\t)\n",
    "\treturn data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_by_area(area='US', df=confirmed).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import make_country_labels, make_state_labels\n",
    "\n",
    "from data import confirmed\n",
    "\n",
    "data = confirmed.copy()\n",
    "print(data.groupby('Country/Region').sum().iloc[:,-1].sort_values(ascending=False).index)\n",
    "\n",
    "\n",
    "make_country_labels(data=confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Country/Region').sum().iloc[:,-2].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_daily_reports(local=True):\n",
    "    start_date = pd.to_datetime('01/22/2020')\n",
    "    end_date = pd.to_datetime('today')\n",
    "    dates = pd.date_range(start_date, end_date)\n",
    "    daily_reports = {}\n",
    "    all_reports = []\n",
    "    if local == True:\n",
    "        print('Getting daily reports using local data')\n",
    "        for date in dates:\n",
    "            date_str = date.strftime('%m-%d-%Y')\n",
    "            file_name = 'data/' + date_str + '.csv'\n",
    "            try:\n",
    "                df = pd.read_csv(file_name, header=0)\n",
    "                df['Date'] = date_str\n",
    "                all_reports.append(df)\n",
    "            except:\n",
    "                print(\"Failed to load {file}\".format(file=file_name))\n",
    "    elif local == False:\n",
    "        print('Getting daily reports using on-line data')\n",
    "        daily_report_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/'\n",
    "        for date in dates:\n",
    "            # File format: 'MM-DD-YYYY.csv'\n",
    "            date_str = date.strftime('%m-%d-%Y')\n",
    "            file_name =date_str + '.csv'\n",
    "            url = daily_report_url + file_name\n",
    "            try:\n",
    "                df = pd.read_csv(file_name, header=0)\n",
    "                df['Date'] = date_str\n",
    "                all_reports.append(df)\n",
    "            except:\n",
    "                print(\"Failed to load {file}\".format(file=file_name))\n",
    "    daily_reports = pd.concat(all_reports, axis=0, ignore_index=True)\n",
    "#    valid_dates = [pd.to_datetime(date) for date in list(daily_reports.keys())]\n",
    "    return daily_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_daily_reports()\n",
    "\n",
    "df['Date']\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "#df['Last Update'] = pd.to_datetime(df['Last Update'])\n",
    "#df['Last Update']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "area = 'US'\n",
    "most_recent = df[df['Country/Region'] == area]['Last Update'].max() - pd.Timedelta('12 hours')\n",
    "df[(df['Country/Region'] == area) & (df['Last Update'] >= most_recent)].sort_values('Last Update', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recent_updates(area='US', timedelta='12 hours', sort='Confirmed', df=None):\n",
    "    ascending = {\n",
    "        'Province/State': True\n",
    "    }\n",
    "    most_recent = df[df['Country/Region'] == area]['Last Update'].max() - pd.Timedelta(timedelta)\n",
    "    return df[\n",
    "        (df['Country/Region'] == area) & (df['Last Update'] >= most_recent)].sort_values(\n",
    "            sort, ascending=ascending.get(sort, False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import data_by_area\n",
    "from data import time_series_dates, confirmed, get_states\n",
    "import numpy as np\n",
    "\n",
    "all_countries = confirmed.groupby('Country/Region').sum()\n",
    "\n",
    "pandemic = 100\n",
    "pandemic_countries = all_countries[all_countries['3/13/20'] >= pandemic].copy()\n",
    "\n",
    "#confirmed[confirmed.columns[4:]].diff(axis=1)/confirmed[confirmed.columns[4:]].plot()\n",
    "\n",
    "ndays = 7\n",
    "data = pandemic_countries[pandemic_countries.columns[-ndays:-1]].copy()\n",
    "data = data.sort_values(list(data.columns)[-1:], ascending=False)\n",
    "\n",
    "rates = (data.diff(axis=1)/data)\n",
    "rates = rates[rates.columns[1:]]\n",
    "rates = rates.sort_values(list(rates.columns)[-1:], ascending=False)\n",
    "\n",
    "from math import log\n",
    "doubling_times = log(2)/rates\n",
    "doubling_times[doubling_times == np.inf]=None\n",
    "#print(doubling_times.mean(axis=1).sort_values())\n",
    "\n",
    "get_states(df=confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nan', 'British Columbia', 'New South Wales', 'Victoria',\n",
       "       'Queensland', 'South Australia', 'From Diamond Princess',\n",
       "       'Western Australia', 'Tasmania', 'Northern Territory', 'Ontario',\n",
       "       'Alberta', 'Quebec', 'Washington', 'New York', 'California',\n",
       "       'Massachusetts', 'Diamond Princess', 'Grand Princess', 'Georgia',\n",
       "       'Colorado', 'Florida', 'New Jersey', 'Oregon', 'Texas', 'Illinois',\n",
       "       'Pennsylvania', 'Iowa', 'Maryland', 'North Carolina',\n",
       "       'South Carolina', 'Tennessee', 'Virginia', 'Arizona', 'Indiana',\n",
       "       'Kentucky', 'District of Columbia', 'Nevada', 'New Hampshire',\n",
       "       'Minnesota', 'Nebraska', 'Ohio', 'Rhode Island', 'Wisconsin',\n",
       "       'Connecticut', 'Hawaii', 'Oklahoma', 'Utah', 'Kansas', 'Louisiana',\n",
       "       'Missouri', 'Vermont', 'Alaska', 'Arkansas', 'Delaware', 'Idaho',\n",
       "       'Maine', 'Michigan', 'Mississippi', 'Montana', 'New Mexico',\n",
       "       'North Dakota', 'South Dakota', 'West Virginia', 'Wyoming',\n",
       "       'Hubei', 'France', 'Guangdong', 'Henan', 'Zhejiang', 'Hunan',\n",
       "       'Anhui', 'Jiangxi', 'Shandong', 'Jiangsu', 'Chongqing', 'Sichuan',\n",
       "       'Heilongjiang', 'Denmark', 'Beijing', 'Shanghai', 'Hebei',\n",
       "       'Fujian', 'Guangxi', 'Shaanxi', 'Yunnan', 'Hainan', 'Guizhou',\n",
       "       'Tianjin', 'Shanxi', 'Gansu', 'Hong Kong', 'Liaoning', 'Jilin',\n",
       "       'Xinjiang', 'Inner Mongolia', 'Ningxia', 'Qinghai', 'Macau',\n",
       "       'Faroe Islands', 'St Martin', 'Channel Islands', 'New Brunswick',\n",
       "       'Tibet', 'Saint Barthelemy', 'Gibraltar',\n",
       "       'Australian Capital Territory', 'United Kingdom',\n",
       "       'French Polynesia', 'Manitoba', 'Saskatchewan', 'Alabama',\n",
       "       'Fench Guiana', 'Puerto Rico', None], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from data import assign_state, confirmed, get_states\n",
    "df = confirmed.copy()\n",
    "df = get_states(df)\n",
    "df['State'].unique()\n",
    "#df['location'] = pd.DataFrame(df['Province/State'].apply(lambda x: assign_state(x)))\n",
    "#df['location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import daily_report_data\n",
    "most_recent = daily_report_data.groupby('Country/Region')['Last Update'].max()[area].to_pydatetime()\n",
    "\n",
    "type(most_recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(np.random.randint(0,10,size=(10, 9)), columns=list('ABCDEFGHI'))\n",
    "#print(df)\n",
    "#print(df.diff(axis=1))\n",
    "df[df.columns[-1:]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
